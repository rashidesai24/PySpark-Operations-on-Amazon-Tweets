{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_Operations_on_Amazon_Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtKa8tEJHT9hOG0AUR1clS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VipanchiKatthula/PySpark_OperationsOnAmazonTweets/blob/master/PySpark_Operations_on_Amazon_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO0wIZfSaUHY",
        "colab_type": "code",
        "outputId": "06d96745-f947-42d8-a06c-03a1480e5753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "路路路路路路路路路路\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpug2kqWfduH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null   #Install Spark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzZYMYHfidR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q http://apache.mirrors.pair.com/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz  #Get Spark Insatller"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZjU3-CiewN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf spark-2.4.5-bin-hadoop2.7.tgz  #Untar Spark installer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcQY55aVlVvR",
        "colab_type": "text"
      },
      "source": [
        "***Install findspark - a python library to find Spark***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5vy-2U9hx9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q findspark   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIj-xZsMlQc_",
        "colab_type": "text"
      },
      "source": [
        "***Setting environmental Variables***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wrEaNy4f64d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHBDXQIlOZi",
        "colab_type": "text"
      },
      "source": [
        "***Create a local Spark session***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azg787TresjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6XKUoxwlGuw",
        "colab_type": "text"
      },
      "source": [
        "***Importing data and Selecting required columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd2yH449bY6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"drive/My\\ Drive/Colab\\ Notebooks/Data/Amazon_Responded_Oct05.csv\")\n",
        "data1 = data.select(\"id_str\",'tweet_created_at','user_verified','favorite_count','retweet_count','text_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ5bzJSMWEdS",
        "colab_type": "text"
      },
      "source": [
        "***Number of rows after filtering for only verified users***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZCmuuiUjm2H",
        "colab_type": "code",
        "outputId": "2d2d1d02-b56c-4e3c-c4f3-bbc25b9004b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dat_filtered = data1.filter(data1.user_verified == 'True')\n",
        "dat_filtered.count() #Selecting only those tweets with vaild/verified users"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "171797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKKDQNfCm43E",
        "colab_type": "code",
        "outputId": "f5b0619c-3866-442d-b036-ad905202217d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "dat_filtered.select(\"tweet_created_at\").show(5,False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+\n",
            "|tweet_created_at              |\n",
            "+------------------------------+\n",
            "|Tue Nov 01 02:39:55 +0000 2016|\n",
            "|Tue Nov 01 17:19:57 +0000 2016|\n",
            "|Tue Nov 01 17:25:26 +0000 2016|\n",
            "|Tue Nov 01 18:02:03 +0000 2016|\n",
            "|Tue Nov 01 03:59:02 +0000 2016|\n",
            "+------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwqFD9WK7xIk",
        "colab_type": "code",
        "outputId": "8fbec7dc-0efe-4859-bbd5-49a45e8e8208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from pyspark.sql.functions import split   #Splitting the date column to parse month date and year.\n",
        "a = split(dat_filtered[\"tweet_created_at\"], ' ')\n",
        "dat_filtered1 = dat_filtered.withColumn('Month', a.getItem(1))\n",
        "dat_filtered1 = dat_filtered1.withColumn('Date', a.getItem(2))\n",
        "dat_filtered1 = dat_filtered1.withColumn('Year', a.getItem(5))\n",
        "dat_filtered1.show(5)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-------------+--------------+-------------+--------------------+-----+----+----+\n",
            "|              id_str|    tweet_created_at|user_verified|favorite_count|retweet_count|               text_|Month|Date|Year|\n",
            "+--------------------+--------------------+-------------+--------------+-------------+--------------------+-----+----+----+\n",
            "|'793281386912354304'|Tue Nov 01 02:39:...|         True|             0|            0|@SeanEPanjab I'm ...|  Nov|  01|2016|\n",
            "|'793502854459879424'|Tue Nov 01 17:19:...|         True|             0|            0|@SeanEPanjab Plea...|  Nov|  01|2016|\n",
            "|'793504235400884224'|Tue Nov 01 17:25:...|         True|             0|            0|@SeanEPanjab With...|  Nov|  01|2016|\n",
            "|'793513446633533440'|Tue Nov 01 18:02:...|         True|             0|            0|@SeanEPanjab I'm ...|  Nov|  01|2016|\n",
            "|'793301295255945216'|Tue Nov 01 03:59:...|         True|             0|            0|@aakashwangnoo Hi...|  Nov|  01|2016|\n",
            "+--------------------+--------------------+-------------+--------------+-------------+--------------------+-----+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cwqBWaYAQKp",
        "colab_type": "code",
        "outputId": "262df875-64be-4c46-a1bd-593cc3186354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import pyspark.sql.functions as sq \n",
        "df = dat_filtered1.withColumn(\"tweet_created_at\",sq.concat(sq.col(\"Month\"), sq.lit(\" \"), sq.col(\"Date\"),sq.lit(\" \"), sq.col(\"Year\")))\n",
        "df = df.select('id_str','tweet_created_at','user_verified',df.favorite_count.cast('int'), df.retweet_count.cast('int'),'text_')\n",
        "df.show(5)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----------------+-------------+--------------+-------------+--------------------+\n",
            "|              id_str|tweet_created_at|user_verified|favorite_count|retweet_count|               text_|\n",
            "+--------------------+----------------+-------------+--------------+-------------+--------------------+\n",
            "|'793281386912354304'|     Nov 01 2016|         True|             0|            0|@SeanEPanjab I'm ...|\n",
            "|'793502854459879424'|     Nov 01 2016|         True|             0|            0|@SeanEPanjab Plea...|\n",
            "|'793504235400884224'|     Nov 01 2016|         True|             0|            0|@SeanEPanjab With...|\n",
            "|'793513446633533440'|     Nov 01 2016|         True|             0|            0|@SeanEPanjab I'm ...|\n",
            "|'793301295255945216'|     Nov 01 2016|         True|             0|            0|@aakashwangnoo Hi...|\n",
            "+--------------------+----------------+-------------+--------------+-------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L93uezclus6n",
        "colab_type": "code",
        "outputId": "b2299418-b1dc-443e-cdee-f520d58d0881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "counts = df.groupby(df.tweet_created_at).agg(sq.count('id_str').alias(\"count_of_tweets\"))\n",
        "counts.show(5)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+---------------+\n",
            "|tweet_created_at|count_of_tweets|\n",
            "+----------------+---------------+\n",
            "|     Dec 01 2016|            875|\n",
            "|     Dec 25 2016|            433|\n",
            "|     Feb 08 2017|            926|\n",
            "|     Feb 19 2017|            725|\n",
            "|     Mar 30 2017|           1109|\n",
            "+----------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zw008cyxPa-",
        "colab_type": "code",
        "outputId": "f5920d8d-aec5-4824-887c-8708a6cb4895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "import pyspark\n",
        "conf = pyspark.SparkConf()\n",
        "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
        "from pyspark.sql import SQLContext\n",
        "sqlcontext = SQLContext(sc)\n",
        "\n",
        "counts.registerTempTable(\"tmpcounts\")\n",
        "counts_ordered = sqlcontext.sql(\"SELECT * FROM tmpcounts order by count_of_tweets desc limit 5\")\n",
        "counts_ordered.show()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+---------------+\n",
            "|tweet_created_at|count_of_tweets|\n",
            "+----------------+---------------+\n",
            "|     Jan 03 2017|           1536|\n",
            "|     Jan 10 2017|           1508|\n",
            "|     Jan 11 2017|           1496|\n",
            "|     Jan 12 2017|           1410|\n",
            "|     Jan 06 2017|           1364|\n",
            "+----------------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktp2XqMXMEKQ",
        "colab_type": "code",
        "outputId": "022ff2ec-4f5b-432a-fa74-2fffa9609222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "df.registerTempTable(\"tmpdf\")\n",
        "sum_retweets = sqlcontext.sql(\"SELECT text_,favorite_count+ retweet_count as total from tmpdf where tweet_created_at = 'Jan 03 2017' order by total desc limit 100\")\n",
        "sum_retweets.show(10,False)\n",
        "text = sum_retweets.toPandas()\n",
        "a =text[\"text_\"].tolist()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|text_                                                                                                                                       |total|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|@amazon worst shopping  experience,  no service, no substantial reply to complaints, no delivery for 1 week post guarantee date.            |5    |\n",
            "|@ItsJosshA We always aim to deliver by the date given in your confirmation email. Have we missed that date? Any update in tracking?  ^NF    |3    |\n",
            "|@ItsJosshA Oh no! I'm sorry! Please reach out to us so that we can look into options: https://t.co/hApLpMlfHN. ^JO                          |2    |\n",
            "|@KStefl Sounds like you know what to add to your Halloween playlist for this year! ^BV                                                      |2    |\n",
            "|@Schoey1992 Happy Birthday, Matt! #FriendsForever #FriendshipGoals ^JO                                                                      |2    |\n",
            "|@ratbones666 You so fancy!!! You already knooow!!! ^EP                                                                                      |2    |\n",
            "|@ThorpPerrow Awww! Happy Birthday, you don't look a day over 20 ;-) .Pass on your details here: https://t.co/g52MRb0AOt for lil surprise ^RS|2    |\n",
            "|@thedexterouz Hi! We'd like to help. When you have a moment, please connect with us here:  https://t.co/vlvfJr4nN9 ^YP                      |2    |\n",
            "|@matt_linsley Please keep us posted on this and let us know if it doesn't arrive tomorrow. ^BV                                              |1    |\n",
            "|@VlSlT Sorry to hear that, contact us here: https://t.co/hApLpMlfHN and we'll look into it for you. ^AS                                     |1    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSCm0ljsRQxw",
        "colab_type": "text"
      },
      "source": [
        "## ***Cleaning Function to remove twitter usernames and punctuation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YneXRoJa9TqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e9ee135a-eeb4-4f36-d75a-3213fb0fc3ad"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        "\n",
        "def cleaning(textfile):\n",
        "    y=textfile\n",
        "    cleaned=[]\n",
        "    for i in y:\n",
        "      # print(i)\n",
        "      i.replace(\"'\", \" \")  #step 1: replacing apostraphe\n",
        "      i=re.sub(r\"\\@\\w+\",\" \",i)   #step2: removing words starting with @\n",
        "      cleaned.append(i.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))) # step 3: remove_punctuation                   \n",
        "    output=[]\n",
        "    for i in cleaned:\n",
        "        output.append(\" \".join([w.lower() for w in i.split()  if w.isalpha()]))    \n",
        "\n",
        "    return output"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkny3UoyStEA",
        "colab_type": "text"
      },
      "source": [
        "***Word frequency and printing it to a .csv file***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol89pKZ9Czbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35c649af-47ce-4a1f-a9dd-247322b793e9"
      },
      "source": [
        "cleaned_text = cleaning(a)\n",
        "from pyspark import SparkContext\n",
        "sc =SparkContext.getOrCreate()\n",
        "k = cleaned_text\n",
        "tuple(k)\n",
        "rdd = sc.parallelize(k)\n",
        "word_frequency_rdd = rdd.flatMap(lambda line: line.split(\" \")) \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b) \\\n",
        "    .collect()\n",
        "print(word_frequency_rdd)\n",
        "tweet_word_frequency_rdd=pd.DataFrame(word_frequency_rdd)\n",
        "tweet_word_frequency_rdd.to_csv(r\"/content/tweet_word_frequency_rdd.csv\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('worst', 1), ('no', 5), ('service', 1), ('substantial', 1), ('delivery', 6), ('week', 1), ('we', 46), ('always', 3), ('in', 13), ('confirmation', 1), ('have', 18), ('update', 2), ('tracking', 5), ('fancy', 1), ('already', 1), ('don', 5), ('look', 7), ('pass', 2), ('details', 6), ('https', 44), ('co', 45), ('lil', 1), ('sounds', 1), ('like', 7), ('know', 13), ('playlist', 1), ('this', 27), ('year', 2), ('bv', 2), ('d', 7), ('help', 9), ('when', 5), ('connect', 1), ('us', 28), ('matt', 1), ('friendshipgoals', 1), ('oh', 1), ('i', 23), ('out', 6), ('into', 6), ('options', 3), ('hear', 4), ('as', 4), ('let', 7), ('doesn', 5), ('arrive', 6), ('tomorrow', 2), ('an', 8), ('ar', 3), ('apologies', 2), ('incorrect', 1), ('item', 5), ('using', 2), ('above', 2), ('do', 4), ('further', 5), ('concerns', 1), ('ca', 1), ('thanks', 11), ('shout', 1), ('looking', 2), ('improve', 1), ('share', 1), ('specific', 1), ('feedback', 7), ('via', 4), ('form', 1), ('sj', 6), ('delay', 1), ('indicate', 1), ('new', 3), ('check', 1), ('updates', 3), ('amazon', 7), ('is', 13), ('est', 1), ('at', 6), ('checkout', 1), ('late', 2), ('cyqkduakwj', 2), ('af', 2), ('s', 7), ('now', 3), ('identify', 1), ('flagging', 1), ('reviewed', 1), ('earliest', 1), ('account', 2), ('but', 3), ('refund', 2), ('en', 3), ('was', 5), ('sent', 1), ('fulfilled', 1), ('third', 2), ('site', 3), ('doug', 1), ('returns', 1), ('items', 1), ('online', 1), ('more', 3), ('seeing', 1), ('advise', 1), ('there', 2), ('getting', 2), ('below', 1), ('pk', 1), ('truly', 2), ('only', 1), ('able', 3), ('end', 1), ('of', 3), ('enjoying', 2), ('collection', 1), ('keeps', 1), ('binge', 1), ('watch', 1), ('feel', 4), ('athena', 1), ('rather', 2), ('delivering', 2), ('things', 1), ('than', 1), ('cold', 1), ('medicine', 1), ('am', 1), ('customer', 2), ('sr', 5), ('card', 2), ('typically', 3), ('process', 1), ('business', 2), ('days', 1), ('requested', 2), ('ve', 2), ('connecting', 1), ('leave', 3), ('way', 2), ('ab', 1), ('waiting', 1), ('carriers', 1), ('until', 2), ('shipment', 1), ('transit', 1), ('destination', 1), ('edd', 1), ('promised', 1), ('inconvenience', 2), ('caused', 1), ('alerts', 2), ('forwarded', 1), ('relevant', 1), ('department', 2), ('jj', 1), ('trouble', 3), ('tried', 1), ('unlinking', 1), ('linking', 1), ('cs', 1), ('sound', 1), ('right', 1), ('support', 3), ('availability', 1), ('payment', 2), ('couriers', 1), ('make', 2), ('sure', 4), ('regret', 1), ('work', 1), ('these', 4), ('instances', 1), ('never', 1), ('happen', 1), ('bringing', 2), ('page', 1), ('investigate', 1), ('hb', 4), ('receiver', 1), ('stopped', 1), ('working', 1), ('very', 1), ('interest', 2), ('phone', 3), ('longer', 1), ('visit', 2), ('mobile', 1), ('browser', 1), ('where', 2), ('newest', 1), ('following', 2), ('steps', 4), ('sb', 1), ('understand', 1), ('showing', 1), ('allow', 1), ('free', 2), ('chat', 2), ('assistance', 1), ('team', 2), ('send', 1), ('use', 1), ('desktop', 1), ('cd', 1), ('concern', 1), ('filled', 1), ('mm', 1), ('didn', 1), ('ask', 1), ('are', 2), ('quality', 1), ('shirt', 1), ('contacted', 2), ('them', 1), ('ra', 1), ('delighted', 1), ('appreciation', 1), ('stayhealthy', 1), ('friendly', 1), ('love', 1), ('certainly', 1), ('try', 3), ('danny', 1), ('may', 2), ('open', 1), ('settings', 1), ('kd', 1), ('tm', 2), ('john', 1), ('recommend', 1), ('website', 1), ('social', 1), ('gl', 3), ('confirm', 1), ('questions', 2), ('li', 1), ('start', 1), ('puppy', 1), ('pretty', 1), ('cute', 1), ('sharing', 1), ('becoming', 1), ('joke', 1), ('speak', 1), ('trying', 1), ('put', 1), ('cutting', 1), ('eligible', 1), ('edit', 1), ('orders', 1), ('letting', 2), ('acct', 1), ('books', 1), ('select', 1), ('vihgdspeur', 1), ('goes', 1), ('mark', 1), ('anything', 1), ('night', 1), ('close', 1), ('click', 1), ('quickly', 1), ('regarding', 1), ('issues', 1), ('hasn', 1), ('qualify', 1), ('claim', 1), ('give', 1), ('other', 1), ('reported', 1), ('looked', 1), ('shopping', 4), ('experience', 9), ('reply', 2), ('to', 65), ('complaints', 1), ('for', 50), ('post', 1), ('guarantee', 3), ('date', 5), ('aim', 2), ('deliver', 4), ('by', 8), ('the', 65), ('given', 1), ('your', 34), ('email', 3), ('missed', 1), ('that', 20), ('any', 8), ('nf', 1), ('you', 64), ('so', 18), ('knooow', 1), ('ep', 2), ('awww', 1), ('happy', 5), ('birthday', 2), ('t', 61), ('a', 25), ('day', 4), ('over', 1), ('on', 14), ('here', 33), ('surprise', 1), ('rs', 2), ('what', 6), ('add', 1), ('halloween', 1), ('hi', 14), ('moment', 1), ('please', 20), ('with', 6), ('yp', 2), ('friendsforever', 1), ('jo', 6), ('m', 13), ('sorry', 21), ('reach', 3), ('can', 28), ('haplpmlfhn', 5), ('contact', 11), ('and', 17), ('ll', 9), ('it', 19), ('keep', 7), ('posted', 6), ('if', 22), ('they', 1), ('direct', 1), ('number', 1), ('bad', 2), ('request', 4), ('return', 5), ('link', 6), ('provided', 3), ('sh', 6), ('hey', 9), ('glad', 3), ('issue', 2), ('has', 3), ('been', 2), ('resolved', 1), ('re', 10), ('pls', 3), ('did', 1), ('e', 2), ('mail', 2), ('order', 10), ('need', 4), ('download', 2), ('video', 2), ('app', 6), ('which', 1), ('separate', 1), ('from', 2), ('how', 3), ('report', 2), ('not', 4), ('cl', 2), ('up', 2), ('ak', 1), ('access', 3), ('through', 3), ('twitter', 2), ('review', 4), ('wrong', 2), ('case', 2), ('being', 1), ('or', 4), ('party', 2), ('seller', 5), ('our', 10), ('arrange', 1), ('most', 3), ('see', 3), ('info', 4), ('cj', 2), ('aren', 1), ('contacting', 1), ('error', 1), ('while', 2), ('redeeming', 1), ('rw', 1), ('directly', 1), ('want', 2), ('customers', 1), ('be', 8), ('aw', 1), ('prime', 1), ('better', 3), ('stay', 1), ('tuned', 1), ('soon', 2), ('much', 2), ('fun', 1), ('features', 1), ('refunds', 1), ('credit', 1), ('within', 1), ('received', 1), ('shall', 1), ('about', 4), ('skgzkjcdng', 1), ('went', 1), ('could', 1), ('elaborate', 1), ('arrived', 3), ('exchange', 2), ('find', 2), ('damaged', 1), ('replacement', 3), ('nxgaalzhis', 1), ('will', 6), ('pm', 1), ('then', 3), ('wj', 4), ('scan', 3), ('indicates', 1), ('should', 2), ('manage', 2), ('text', 1), ('spotify', 1), ('alexa', 1), ('time', 3), ('unable', 2), ('mpos', 1), ('device', 1), ('cod', 1), ('vs', 1), ('create', 1), ('stock', 2), ('same', 1), ('place', 1), ('its', 1), ('isn', 2), ('repeated', 1), ('attention', 2), ('list', 1), ('me', 3), ('next', 1), ('thank', 1), ('windows', 1), ('application', 1), ('available', 2), ('encourage', 1), ('cancel', 1), ('membership', 1), ('hope', 3), ('helps', 3), ('concerned', 1), ('expected', 1), ('status', 2), ('some', 3), ('real', 1), ('td', 1), ('kindle', 3), ('teams', 2), ('assist', 2), ('hg', 2), ('ctrl', 1), ('f', 1), ('address', 1), ('get', 3), ('kindly', 1), ('drop', 1), ('shared', 1), ('earlier', 2), ('asked', 1), ('receive', 1), ('reviews', 1), ('written', 1), ('w', 2), ('purchased', 1), ('product', 1), ('happynewyear', 1), ('packages', 1), ('ja', 3), ('shoutout', 1), ('knowing', 1), ('helped', 1), ('updated', 1), ('sorted', 2), ('ae', 3), ('menu', 1), ('packaging', 1), ('submit', 1), ('amp', 1), ('picture', 1), ('checking', 1), ('media', 1), ('back', 1), ('frustrating', 1), ('reading', 1), ('lg', 1), ('paw', 1), ('supervisor', 1), ('colleagues', 1), ('off', 1), ('still', 1), ('modify', 1), ('method', 1), ('great', 2), ('evening', 1), ('else', 1), ('yourself', 1), ('recent', 1), ('location', 1), ('cleared', 1), ('customs', 1), ('view', 1), ('were', 1), ('ship', 1), ('fitbit', 1), ('arrives', 1), ('information', 1), ('rm', 1), ('z', 1), ('found', 1), ('had', 1), ('internally', 1), ('patience', 1), ('hk', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1En5ThVIEo",
        "colab_type": "text"
      },
      "source": [
        "## ***Task -2***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcJvi2WVVHay",
        "colab_type": "code",
        "outputId": "14030847-3f41-406a-fa8f-4456e29b399a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "finddata = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"drive/My\\ Drive/Colab\\ Notebooks/Data/find_text.csv\")\n",
        "finddata.show(5,False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|id_str              |text|\n",
            "+--------------------+----+\n",
            "|'793270689780203520'|null|\n",
            "|'793281386912354304'|null|\n",
            "|'793299404975247360'|null|\n",
            "|'793301295255945216'|null|\n",
            "|'793315815411978240'|null|\n",
            "+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suYS4H5jVvg4",
        "colab_type": "code",
        "outputId": "c7a48bef-1f8d-47ed-81da-28c03ef6b248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "finddata.registerTempTable(\"ids\")\n",
        "data.registerTempTable(\"tweets\")\n",
        "out = sqlcontext.sql(\"SELECT DISTINCT I.id_str,T.text_ from ids I JOIN tweets T on I.id_str = T.id_str\")\n",
        "out.show(5,False)\n",
        "output = out.toPandas()\n",
        "output.to_csv(r\"/content/join_output.csv\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id_str              |text_                                                                                                                                    |\n",
            "+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|'793382930085253121'|@mybharatraj Hi! Sorry about that. I'd like our team to look into this, please reach out to us via: https://t.co/vlvfJr4nN9 ^SG          |\n",
            "|'793441656984903680'|@AmazonHelp done, please contact them and let them know I am waiting for my package.                                                     |\n",
            "|'793517259880861696'|Your customer service sucks, @AmazonHelp. If you guys can't do your job, perhaps go back to school and learn something proper.           |\n",
            "|'793533066157387776'|@flamablebrownie When checking your account, are you signed into the email that was used to place the order: https://t.co/aaDyEz1VgE? ^HB|\n",
            "|'793542659625349121'|So now @AmazonHelp is helping my hacker instead of helping me. Good job.  Why do you even have a help centre if you're of no help?     |\n",
            "+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}